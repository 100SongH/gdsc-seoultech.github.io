# 알고리즘 체인과 파이프라인

이번 장에서는 데이터 변환 과정과 머신러닝 모델을 쉽게 연결해주는 Pipeline 파이썬 클래스를 배운다. 특히 Pipeline과 GridSearchCV를 함께 사용해서 각 처리 단계에서 필요한 매개변수 탐색을 동시에 수행한다.

![image](https://user-images.githubusercontent.com/66999675/142610318-31a78406-3d08-4813-b7c9-e9ef27817d71.png)

교차 검증 밖에서 전처리가 될 때 주의할 점이 있다.  
먼저 데이터의 최솟값과 최댓값을 계산할 때 학습을 위해서 훈련 세트에 있는 모든 데이터를 사용한다. 그 다음 스케일이 조정된 훈련 데이터 사용해서 그리드 서치를 수행한다. 교차 검증의 각 분할에서 원본 훈련 세트 데이터의 어떤 부분은 훈련 폴드가 되고 어떤 부분은 검증 폴드가 된다. 검증 폴드는 훈련 폴드로 학습된 모델이 새로운 데이터에 적용될 때의 성능을 측정하는 데 사용한다. 하지만 **데이터 스케일을 조정할 때** 이미 검증 폴드에 들어 있는 정보까지 사용했습니다. 다시 말하면 교차 검증의 반복마다 선택된 검증 폴드는 전체 훈련 세트의 일부이고, 데이터 스케일을 조정하기 위해서 전체 훈련 세트를 사용했다. 하지만 이는 새로운 데이터가 모델에 나타날 때와 완전히 다르다. 새로운 데이터가 관측되면 이 데이터는 훈련 데이터의 스케일 조정에 사용되지 않은 것이라, 그 최솟값과 최댓값이 훈련 데이터와 다를 수 있다.

위와 같은 이유로 교차 검증의 분할 방식은 모델이 새 데이터를 만났을 때 올바르게 반영하지 못 한다.

이 문제를 해결하려면 교차 검증의 분할이 모든 전처리 과정보다 앞서 이뤄져야한다.  
데이터셋의 정보를 이용하는 모든 처리 과정은 데이터셋의 훈련 부분에만 적용되어야 하기에 교차 검증 반복 안에 있어야한다.

scikit-learn에서 cross_val_score 함수와 GridSearchCV로 이런 방식을 구현하려면 Pipeline을 사용하면 된다. Pipeline은 여러 처리 단계를 하나의 scikit-learn 추정기 형태로 묶어주는 파이썬 클래스이다. Pipeline은 fit,predict,score 메서드를 제공한다.  
Pipeline은 분류기 같은 지도 학습 모델과 데이터 스케일 조정 같은 전처리 단계를 연결할 때 사용한다.

# 파이프라인 구축하기

![image](https://user-images.githubusercontent.com/66999675/142612577-24f06623-16f1-4756-b612-a12842c89f94.png)

```python
from sklearn.pipeline impot Pipeline
```

으로 파이프라인 사용 가능합니다. MinMaxScaler로 데이터 스케일을 조정하고 SVM 모델을 훈련 시키는 파이프라인입니다. 각 단계를 리스트로 전달해서 파이프라인 객체를 만듭니다. 각 단계는 추정기의 객체와 임의의 이름(아무 문자열 가능하지만 이중 밑줄 문자는 안됨)으로 구성된 tuple

```python
pipe.fit(x_train,y_train)
pipe.score(x_test,y_test)
```

fit을 이용하면 첫 번째 단계(scaler)의 fit 메서드를 호출해서 훈련 데이터를 변환하고, 마지막으로 변환된 데이터에 svm 모델을 훈련시킨다. 테스트 세트로 평가하려면 pipe.score를 호출하면 된다.

score 메서드를 호출하면, scaler를 사용해서 테스트 데이터를 변환하고, 변환된 데이터에 SVM 모델의 score 메서드를 호출한다.  
파이프라인을 사용하면 전처리 + 분류 과정을 위해 작성해야 할 코드가 줄어들고 cross_val_score나 GridSearchCV에 파이프라인을 하나의 추정기처럼 사용할 수 있다는 것이다.

# 그리드 서치에 파이프라인 적용하기

그리드 서치에 파이프라인을 사용하는 방식 역시 다른 추정기를 사용할 때와 같다. 탐색할 매개변수 그리드를 정의하고, 이 매개변수 그리드와 파이프라인으로 GridSearchCV의 객체를 만든다. 이때 매개변수 그리드를 만들 때 각 매개변수가 파이프라인의 어떤 단계에 속한 것인지 알려줘야한다. C와 gamma 매개변수는 두 번째 단계인 SVC의 매개변수이다. 앞에서 이 단계의 이름을 SVM이라고 지정했기에 매개변수 이름을 \_\_ 로 연결해서 만든다.

```python
param_grid = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100],
              'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}
```

![image](https://user-images.githubusercontent.com/66999675/142614263-30553b00-b92b-4f60-b3db-cde06d051af7.png)

교차 검증 반복 안에서 전처리가 될 때 데이터 사용 형태이다. 교차 검증의 가 분할에 MinMaxScaler가 훈련 폴드에 매번 적용되어, 매개변수 검색 과정에 검증 폴드의 정보가 누설되지 않는다.

# 파이프라인 인터페이스

pipeline은 전처리나 분류에 국한하지 않고 어떤 추정기와도 연결할 수 있다. 예를 들어 특성 추출, 특성 선택, 스케일 변경, 분류의 총 네 단계를 포함하는 파이프라인을 만들 수 있다. 비슷하게, 마지막 단계가 분류 대신 회귀나 군집이 될 수도 있다.

파이프라인에 들어갈 추정기는 마지막 단계를 제외하고는 모두 **transform 메서드**를 가지고 있어야한다. 그래서 다음 단계를 위한 새로운 데이터 표현을 만들 수 있어야한다.

내부적으로는 Pipeline.fit 메서드가 실행되는 동안, 파이프라인은 각 단계에서 이전 단계의 transform의 출력을 입력으로 받아 fit과 transform 메서드를 차례로 호출한다. 그리고 마지막 단계는 fit 메서드만 호출한다.

Pipeline을 사용해서 예측할 때는, 비슷한 방식으로 마지막 단계 이전까지 transform 메서드를 호출한 다음, 마지막 단계에서 predict를 호출한다.

# make_pipleline을 사용한 파이프라인 생성

make_pipeline 함수는 각 단계 이름에 해당 파이선 클래스의 이름을 부여한 파이프라인을 만들어준다.

```python
from sklearn.pipeline import make_pipeline
pipe_long = Pipeline([("scaler",MinMaxScaler()),("svm",SVC(C=100))])
```

기존의 파이프라인은 위와 같이 이름을 부여해줬어야 했다.

```python
pipe_short = make_pipeline(MinMaxScaler(),SVC(C=100))
```

make_pipeline을 이용하면 자동으로 이름을 만들어준다.

단계의 이름은 steps 속성에서 알 수 있고 일반적으로 이름은 파이썬 클래스 이름의 소문자 버전이다. 같은 파이썬 클래스를 여러 단계에서 사용하면 이름 뒤에 숫자가 추가로 붙는다.

파이프라인의 각 단계에 접근 할려면 name_steps를 이용하면된다.
그리드 서치를 사용했을 때도 각 단계에 접근하려면 똑같이 name_steps를 사용하면 된다.

# 전처리와 모델의 매개변수를 위한 그리드 서치

파이프라인을 사용하면 머신러닝 워크플로에 필요한 모든 처리 단계를 하나의 scikit-learn 추정기로 캡슐화 할 수 있다. 또 다른 장점으로, 회귀와 분류 같은 지도 학습의 출력을 이용해서 전처리 매개변수를 조정할 수 있다.

모델의 매개변수와 함께 전처리 과정의 매개변수를 찾는 것은 매우 강력한 전략이다. 하지만 GridSearchCV는 지정한 매개변수의 모든 가능한 조합을 시도한다. 그렇기에 매개변수 그리드에 많은 매개변수를 추가하면 만들어야 할 모델이 급격히 증가하게 된다.

# 모델 선택을 위한 그리드 서치

GridSearchCV와 Pipeline을 연결하는 것에서 더 나아가, 파이프라인을 구성하는 단계도 탐색 대상으로 삼을 수 있다. 이렇게 하면 탐색 범위가 더 넓어지므로 주의 깊게 고려해야 한다.

### 중복 계산피하기

대규모 그리드 서치를 수행할 때는 종종 동일한 단계가 여러 번 수행된다. 비용이 적으면 상관없지만 비용이 많이 드는 변환을 사용하면 계산 낭비가 심해진다. 가장 간단한 해결책은 파이프라인의 memory 매개변수를 사용해서 계산 결과를 캐싱하는 것이다. 이 매개변수는 joblib.memory 객체나 캐싱할 경로를 받는다.

```python
    memory = 'cache_folder'
```

하지만 이 방법에는 두 가지 단점이 있다. cache는 디스크에 저장되어 관리하기에 실제 디스크에 읽고 쓰기 위해 직렬화가 필요하다. 즉 비교적 오랜 시간이 걸리는 변환이어야 memory 매개변수를 사용해서 속도를 높이는 효과를 낼 수 있다.  
또 다른 단점으론 n_jobs 매개변수가 캐싱을 방해한다는 것이다. 그리드 서치의 실행 순서에 따라 최악의 경우 캐시되기 전에 n_jobs 만큼의 작업 프로세스가 동시에 동일한 계산을 중복으로 수행할 수 있다. dask-ml 라이브러리에서 제공하는 GridSearchCV를 사용하면 이런 단점을 모두 피할 수 있다. dask-ml은 병렬 연산을 수해아는 동안 중복된 계산을 방지한다. 심지어 클러스터에 분산된 경우에도 가능하다.
