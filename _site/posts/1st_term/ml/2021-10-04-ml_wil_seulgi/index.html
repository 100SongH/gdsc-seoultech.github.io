<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="tYMwPoxNrWfLx2sDrDYzqI4-dq3M3FfI56NBL9JNtH8" />

    <title>4주차 ML WIL</title>
    <meta name="description" content="A simple, whitespace, helvetica based portfolio theme.
">

    <link rel = "shortcut icon" type="image/x-icon" href="/img/square_logo.png">
    <link rel="stylesheet" href="/css/main.css">
<!--    <link rel="canonical" href="http://localhost:4000/posts/1st_term/ml/2021-10-04-ml_wil_seulgi/">-->
    <link rel="canonical" href="/posts/1st_term/ml/2021-10-04-ml_wil_seulgi/">

    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

    <!-- 카테고리 css -->
    <link rel="stylesheet" href="/css/pagination.css">
    <link href="/css/category.css" type="text/css" rel="stylesheet">
</head>

   
  <body>
    <script src="/js/default.js"></script>
    <header id="tab" >
  <script src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
  <div class="site-header">
    <div class="wrapper">
      <div>
        <a href="/">
          <img src="/img/square_logo.png" align="left" width="57px">
        </a>
      </div>

      <nav class="site-nav">

        <div id="tab" class="trigger">
          <!-- GDSC Seoultech instead of blog -->
          <a class="page-link" href="/">GDSC</a>
          <a class="page-link" href="/members/2">MEMBER</a>
          <a class="page-link" href="/category/2nd_term">POST</a>
        </div>
      </nav>
    </div>
  </div>

  <div id="hovering" class="tab-header">
    <div class="wrapper">
      <div class="detail-post">
          <div class="tab-item">
            <div><a class="page-link-detail" href="/category/1st_term">1기</a></div>
            <div><a class="page-link-detail" href="/category/2nd_term">2기</a></div>
          </div>
      </div>
      <div class="detail-member">
        <div class="tab-item">
          <div><a class="page-link-detail" href="/members/1">1기</a></div>
          <div><a class="page-link-detail" href="/members/2">2기</a></div>
        </div>
    </div>
    </div>

  </div>

  <script type="text/javascript">
    var tabMenu = $("#tab");
    var tabSubMenu = $("#hovering");

    tabSubMenu.hide()

    tabMenu.hover(function() {
      tabSubMenu.show();
    }, function() {
      tabSubMenu.hide();
    })
  </script>

</header>


    <div class="page-content" id="page-content">
      <div class="wrapper" id="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">4주차 ML WIL</h1>
    <h1 class="post-description"></h1>
    <p class="post-meta">October 3, 2021 — 23:00 • ssggi</p>
    
      
        <span class="tag">ml</span>
      
    
  </header>
  <article class="post-content">
    <h1 id="결정-트리">결정 트리</h1>

<p>결정트리는 분류와 회귀 문제에 널리 사용하는 모델
예/아니오 질문을 이어나가며 학습한다
<br /></p>
<ul>
  <li><strong>노드</strong> : 질문이나 정답을 담은 네모 상자. 맨 위 노드는 <strong>루트 노드</strong>라 불리고, 마지막 노드는 <strong>리프</strong>라고도 한다.</li>
  <li><strong>에지</strong>는 질문의 답과 다음 질문을 연결한다.
<br /></li>
</ul>

<blockquote>
  <h3 id="결정트리-만들기">결정트리 만들기</h3>
</blockquote>

<ul>
  <li>데이터셋 : two_moons 사용
<br /></li>
  <li>결정 트리를 학습한다는 것 -&gt; 정답에 가장 빨리 도달하는 예/아니오 질문 목록을 학습한다는 것</li>
  <li>머신러닝에서 이런 질문들을 <strong>테스트</strong>라고 한다.</li>
</ul>

<hr />
<p>가장 좋은 테스트를 찾는 과정을 반복해서 모델을 더 정확하게 만들 수 있다.</p>

<ul>
  <li>반복된 프로세스는 각 노드가 테스트 하나씩을 가진 <strong>이진 결정 트리</strong>를 만든다 (True/False)</li>
  <li>즉 각 테스트는 하나의 축을 따라 데이터를 둘로 나눈다</li>
  <li>
    <p>계층적으로 영역을 분할해가는 알고리즘이며 각 테스트는 하나의 특성에 대해서만 이루어지므로 나누어진 영역은 항상 축에 평행</p>
  </li>
  <li>
    <p>데이터를 분할하는 것은 각 분할된 영역이 (결정 트리의 리프) 한 개의 타깃값(하나의 클래스나 회귀 분석 결과)을 가질 때까지 반복!</p>
  </li>
  <li>타깃 하나로만 이루어진 리프 노드를 <strong>순수 노드</strong>라고 한다.</li>
</ul>

<hr />

<p>새로운 데이터 포인트에 대한 예측은 주어진 데이터 포인트가 특성을 분할한 영역들 중 어디에 놓이는지를 확인,<br />
그 영역의 타깃 값 중 다수인 것을 예측 결과로 한다. 
<em>순수 노드라면 하나!</em>
<br /></p>
<ul>
  <li><strong>회귀</strong> 문제에도 트리 사용 가능<br />
같은 방법으로 새로운 데이터 포인트에 해당되는 리프 노드를 찾고, 찾은 리프 노드의 훈련 데이터 평균값이 이 데이터 포인트의 출력
<br /></li>
</ul>

<blockquote>
  <h3 id="결정-트리의-복잡도-제어하기">결정 트리의 복잡도 제어하기</h3>
</blockquote>

<p>과대적합을 막는 전략</p>

<ol>
  <li><strong>사전 가지치기</strong> : 트리의 최대 깊이나 리프의 최대 개수를 제한하거나, 노트가 분할하기 위한 포인트의 최소 개수를 지정</li>
  <li><strong>사후 가지치기</strong> : 트리를 만든 후 데이터 포인트가 적은 노드를 사용하거나 병합
<br /></li>
</ol>

<blockquote>
  <h3 id="트리의-특성-중요도">트리의 특성 중요도</h3>
</blockquote>

<p>전체 트리를 살펴보는 것 대신, 트리가 어떻게 작동하는지 요약하는 속성을 사용할 수 있음</p>
<ul>
  <li>
    <p><strong>특성 중요도</strong> : 각 특성이 트리를 만드는 결정에 얼마나 중요한지를 평가.
0과 1 사이의 숫자로 1에 가까울 수록 중요한 특성.
특성 중요도의 전체 합은 1.</p>
  </li>
  <li>
    <p>분류 트리와 달리 회귀 결정 트리 DecisionTreeRegressor는 <strong>외삽</strong>, 즉 훈련 데이터의 범위 밖의 포인트에 대해 예측할 수 없다.
<br /></p>
  </li>
</ul>

<blockquote>
  <h3 id="장단점과-매개변수">장단점과 매개변수</h3>
</blockquote>

<p>결정 트리에서 모델 복잡도를 조절하는 매개변수는 사전 가지치기 매개변수 (사이킷런은 사전 가지치기만 지원)</p>
<ul>
  <li>max_depth, max_leaf_nodes, min_samples_leaf</li>
</ul>

<p>결정 트리의 장점</p>
<ul>
  <li>만들어진 모델을 쉽게 시각화할 수 있음</li>
  <li>데이터의 스케일의 영향을 받지 않아 특성의 정규화나 표준화 같은 전처리 과정 필요 없음</li>
  <li>스케일이 서로 다르거나 특성이 혼합되어 있을 때도 잘 작동</li>
</ul>

<p>주요 단점</p>
<ul>
  <li>사전 가지치기를 사용함에도 불구하고 과대적합 되는 경향
<br /></li>
</ul>

<h1 id="결정-트리의-앙상블">결정 트리의 앙상블</h1>

<p><strong>앙상블</strong> : 여러 머신러닝 모델을 연결하여 더 강력한 모델을 만드는 기법<br />
<br />
분류와 회귀 모델의 다양한 데이터셋에서 효과적인 모델 
–&gt; <strong>랜덤 포레스트</strong>와 <strong>그레이디언트 부스팅</strong>~!!<br />
<br /></p>

<blockquote>
  <h3 id="랜덤-포레스트">랜덤 포레스트</h3>
</blockquote>

<ul>
  <li>랜덤 포레스트는 기본적으로 조금씩 다른 여러 결정 트리의 묶음</li>
  <li>
    <p>잘 작동하되 서로 다른 방향으로 과대적합된 트리를 많이 만들고, 그 결과를 평균냄으로써 과대적합된 양을 줄일 수 있다.<br />
–&gt; 예측 성능 유지, 과대적합 줄임</p>
  </li>
  <li>트리 생성 시 트리들이 달라지도록 무작위성을 주입.
    <ol>
      <li>트리를 만들 떄 사용하는 <strong>데이터 포인트</strong>를 무작위로 선택</li>
      <li>분할 테스트에서 <strong>특성</strong>을 무작위로 선택<br />
<br /></li>
    </ol>
  </li>
</ul>

<blockquote>
  <h3 id="랜덤-포레스트-구축">랜덤 포레스트 구축</h3>
</blockquote>

<p>생성할 트리의 개수를 정한다. - n_estimators 매개변수</p>

<p>각 트리를 완전히 독립적으로 만들기 위해 먼저 데이터의 <strong>부트스트랩 샘플</strong>을 생성.<br />
(n_samples개의 데이터 포인트 중에서 무작위로 데이터를 n_samples 횟수만큼 반복 추출한다)<br />
<br />
특성의 개수는 max_feature 매개변수로 조정 가능</p>

<p>이렇게 만든 데이터셋으로 결정트리를 만듦</p>
<ul>
  <li>부트스트랩 샘플링을 통해 랜덤 포레스트의 트리가 조금씩 다른 데이터셋으로 만들어지게 됨</li>
  <li>각 노드에서 특성의 일부만 사용하기 때문에 트리의 각 분기는 각기 다른 특성의 부분 집합을 사용<br />
–&gt; 랜덤 포레스트의 모든 트리가 서로 달라짐</li>
</ul>

<p><strong>매개변수 max_features</strong><br />
max_features의 값을 크게 하면 트리들은 매우 비슷해지고 가장 두드러진 특성을 이용해 데이터에 잘 맞춰짐<br />
값을 낮추면 트리들은 많이 달라지고 각 트리는 데이터에 맞추기 위해 깊이가 깊어짐<br />
<br /></p>

<blockquote>
  <h3 id="장단점과-매개변수-1">장단점과 매개변수</h3>
</blockquote>

<ul>
  <li>성능이 매우 뛰어나고 매개변수 튜닝을 많이 하지 않아도 잘 작동하며 데이터의 스케일을 맞출 필요가 없다</li>
  <li>텍스트 데이터처럼 차원이 높고 희소한 데이터에는 잘 작동하지 않음</li>
  <li>선형 모델보다 많은 메모리를 사용하며 훈련과 예측이 느림<br />
<br /></li>
  <li>중요 매개변수는 n_estimators, max_features, max_depth같은 사전 가지치기 옵션  <br /></li>
  <li>n_estimators는 클수록 좋다. 
–&gt; 더 많은 트리를 평균하면 과대적합 줄여 더 안정적인 모델 생성 but 긴 훈련 시간 ㅜㅜ<br />
<br /></li>
</ul>

<blockquote>
  <h3 id="그래디언트-부스팅-회귀-트리">그래디언트 부스팅 회귀 트리</h3>
</blockquote>

<p>여러 개의 결정 트리를 묶어 강력한 모델을 만드는 또 다른 앙상블 방법<br />
(회귀와 분류 모두에 사용 가능)</p>

<ul>
  <li>이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듦</li>
  <li>무작위성이 없는 대신 사전 가지치기가 사용됨</li>
  <li>메모리를 적게 사용하고 예측이 빠른 것이 특징<br />
<br /></li>
  <li>얕은 트리 같은 간단한 모델(<strong>약한 학습기</strong>)을 많이 연결하는 것이 근본적인 아이디어</li>
  <li>각각의 트리는 일부 데이터에만 예측을 잘 수행할 수 있어 트리가 많이 추가될수록 성능이 좋아짐<br />
<strong>learning rate(학습률)</strong></li>
  <li>학습률이 크면 트리는 오차를 강하게 보정, 복잡한 모델 생성<br />
<br /></li>
</ul>

<blockquote>
  <h3 id="장단점과-매개변수-2">장단점과 매개변수</h3>
</blockquote>

<ul>
  <li>매개변수를 잘 조절해야한다는 것과 훈련 시간이 길다는 단점이 있음
<br /></li>
  <li>중요 매개변수는 <strong>n_estimators</strong>(트리의 개수를 지정)와 <strong>learning_rate</strong>(트리의 오차를 보정하는 정도를 조절)</li>
  <li>n_estimators가 클수록 모델이 복잡해지고 과대적합될 가능성이 높아짐</li>
  <li>learning_rate를 낮추면 비슷한 복잡도의 모델을 많이 만들기 위해 더 많은 트리를 추가해야함 - 뭔 말이지?</li>
  <li>max_depth 또는 max_leaf_nodes (각 트리의 복잡도를 낮춤)<br />
<br /></li>
</ul>

<h3 id="배깅-엑스트라-트리-에이다부스트">배깅, 엑스트라 트리, 에이다부스트</h3>

<blockquote>
  <h3 id="배깅">배깅</h3>
</blockquote>

<p>Bootstrap aggregating의 줄임말<br />
중복을 허용한 랜덤 샘플링으로 만든 훈련 세트를 사용하여 분류기를 각기 다르게 학습시킴</p>
<ul>
  <li>분류기가 predict_proba() 메서드를 지원하는 경우 확률값을 평균하여 예측을 수행함</li>
  <li>그렇지 않은 분류기에서는 가장 빈도가 높은 클래스 레이블이 예측 결과가 됨
<br /></li>
</ul>

<blockquote>
  <h3 id="엑스트리-트리">엑스트리 트리</h3>
</blockquote>

<p>랜덤 포레스트와 비슷하지만 후보 특성을 무작위로 분할한 다음 최저의 분할을 찾음</p>
<ul>
  <li>DecisionTreeClassifier 사용, 부트스트랩 샘플링은 적용하지 않음</li>
  <li>무작위성을 증가시키면 모델의 편향 증가, 분산 감소</li>
  <li>예측 방식: 각 트리가 만든 확률값을 평균함</li>
  <li>
    <dl>
      <dt>일반적으로 랜덤 포레스트가 더 선호된다.</dt>
      <dd>엑스트라 트리가 랜덤 포레스트보다 계산 비용이 적지만 무작위 분할 때문에 일반화 성능을 높이려면 많은 드리를 만들어야 함
<br /></dd>
    </dl>
  </li>
</ul>

<blockquote>
  <h3 id="에이다부스트">에이다부스트</h3>
</blockquote>

<p>Adaptive Boostion의 줄임말<br />
약한 학습기를 사용, 이전의 모델이 잘못 분류한 샘플에 가중치를 높여서 다음 모델을 훈련시킴</p>
<ul>
  <li>훈련된 각 모델은 성능에 따라 가중치가 부여됨</li>
  <li>예측 방식: 모델이 예측한 레이블을 기준으로 모델의 가중치를 합산하여 가장 높은 값을 가진 레이블을 선택!</li>
</ul>

<h1 id="커널-서포트-벡터-머신">커널 서포트 벡터 머신</h1>
<p>입력 데이터에서 단순한 초평면으로 정의되지 않는 더 복잡한 모델을 만들 수 있도록 확장한 것</p>

<blockquote>
  <h3 id="선형-모델과-비선형-특성">선형 모델과 비선형 특성</h3>
</blockquote>

<p>선형 모델을 유연하게 만드는 방법은 특성끼리 곱하거나 특성을 거듭제곱하는 식으로 새로운 특성을 추가하는 것</p>

<blockquote>
  <h3 id="커널-기법">커널 기법</h3>
</blockquote>

<p>실제로 데이터를 확장하지 않고 확장된 특성에 대한 데이터 포인트들의 거리를 계산</p>
<ul>
  <li>SVM에서 데이터를 고차원 공간에 매핑하는 법
    <ol>
      <li>원래 특성의 가능한 조합을 지정된 차수까지 모두 계산하는 <strong>다항식 커널</strong></li>
      <li>
        <dl>
          <dt>가우시안 커널로도 불리는 <strong>RBF 커널</strong></dt>
          <dd>차원이 무한한 특성 공간에 매핑하는 것으로 모든 차수의 모든 다항식을 고려함 
특성의 중요도는 고차항이 될수록 줄어듦(지수 함수의 테일러 급수 전개 때문 - ???)</dd>
        </dl>
      </li>
    </ol>
  </li>
</ul>

<blockquote>
  <h3 id="svm-이해하기">SVM 이해하기</h3>
</blockquote>

<p>일반적으로 두 클래스 사이의 경계에 위치한 훈련 데이터의 일부만 결정 경계를 만드는 데 영향을 준다. 이런 데이터 포인트를 <strong>서포트 벡터</strong>라고 한다.</p>

<p>새로운 데이터 포인트에 대한 분류 결정은 서포트 벡터까지의 거리에 기반, 서포트 벡터의 중요도는 훈련 과정에서 학습!</p>

<blockquote>
  <h3 id="svm-매개변수-튜닝">SVM 매개변수 튜닝</h3>
</blockquote>

<ol>
  <li>gamma 매개변수
    <ul>
      <li>rambda로, 가우시안 커널 폭의 역!수!</li>
      <li>하나의 훈련 샘플이 미치는 영향의 범위를 결정</li>
      <li>가우시안 커널의 반경이 클수록 훈련 샘플의 영향 범위도 커짐</li>
    </ul>
  </li>
  <li>C 매개변수
    <ul>
      <li>규제 매개변수. 각 포인트의 중요도를 제한함.</li>
    </ul>
  </li>
  <li>정리
    <ul>
      <li>gamma 매개변수가 커지면 모델 복잡도 증가</li>
      <li>작은 C 매개변수는 매우 제약이 큰 모델을 만들고 각 데이터 포인트의 영향력이 작음</li>
      <li>C 매개변수가 커지면 더 복잡한 모델을 만듦</li>
    </ul>

    <p><em>gamma, C 둘 다 값이 커지면 모델이 복잡해지는 거임</em></p>
  </li>
</ol>

<blockquote>
  <h3 id="svm을-위한-데이터-전처리">SVM을 위한 데이터 전처리</h3>
</blockquote>

<ul>
  <li>모든 특성 값을 평균이 0이고 단위 분산이 되도록 하거나, 0과 1 사이로 맞추는 방법을 많이 사용</li>
  <li>C나 gamma 값을 증가시켜 좀 더 복잡한 모델을 만들 수 있다.</li>
</ul>

<blockquote>
  <h3 id="장단점과-매개변수-3">장단점과 매개변수</h3>
</blockquote>

<ul>
  <li>SVM은 데이터셋의 특성이 몇 개 안 되더라도 복잡한 결정 경계를 만들 수 있다</li>
  <li>저차원과 고차원(특성이 적거나 많을 때)에 모두 잘 동작하지만 샘플이 많을 때는 잘 맞지 않음</li>
  <li>데이터 전처리와 매개변수 설정에 신경을 많이 써야 함</li>
  <li>분석하기 어려움
<br /></li>
  <li>커널 SVM에서 중요한 매개변수는 규제 매개변수인 <strong>C</strong></li>
  <li>RBF 커널은 가우시안 커널 폭의 역수인 <strong>gamma</strong> 매개변수를 가짐</li>
  <li>C와 gamma 모두 큰 값이 더 복잡한 모델을 만든다
<br /></li>
</ul>

<h1 id="신경망딥러닝">신경망(딥러닝)</h1>

<p><strong>다층 퍼셉트론</strong>은 복잡한 알고리즘의 출발점이며 비교적 간단하게 분류와 회귀에 쓸 수 있다.</p>
<ul>
  <li>피드포워드 신경망 또는 그냥 신경망이라고도 함</li>
</ul>

<blockquote>
  <h3 id="신경망-모델">신경망 모델</h3>
</blockquote>

<p><strong>MLP</strong> <em>multi-layer perceptron</em> 는 여러 단계를 거쳐 결정을 만들어내는 선형 모델의 일반화된 모습이라고 볼 수 있다</p>

<p>&lt;그림 2-44&gt;의 <strong>왼쪽 노드는 입력 특성</strong>을 나타내며
<strong>연결선은 학습된 계수</strong>를 표현하고
<strong>오른쪽 노드는 입력의 가중치 합, 즉 출력</strong>을 나타낸다</p>

<ul>
  <li>
    <p>MLP에서 가중치 합을 만드는 과정이 여러 번 반복됨</p>
  </li>
  <li>
    <p><strong>계수</strong>는 각 입력과 은닉층의 은닉 유닛 사이, 그리고 각 은닉 유닛과 출력 사이마다 있다</p>
  </li>
</ul>

<p>신경망 모델을 선형 모델보다 강력하게 만들기 위해 각 은닉 유닛의 가중치 합을 계산한 후 그 결과에 비선형 함수인 <strong>렐루</strong>나 <strong>하이퍼볼릭 탄젠트</strong>를 적용한다.</p>
<ul>
  <li>ReLU는 0 이하를 잘라버리고, tanh 함수는 낮은 입력값에 대해서는 -1로 수렴하고 큰 입력값에 대해서는 +1로 수렴한다.</li>
</ul>

<p>비선형 함수를 이용하여 신경망이 더 복잡한 함수 학습하게 됨
<br /></p>

<blockquote>
  <h3 id="장단점과-매개변수-4">장단점과 매개변수</h3>
</blockquote>

<ul>
  <li>대량의 데이터에 내재된 정보를 잡아내고 매우 복잡한 모델을 만들 수 있다</li>
  <li>크고 강력한 모델에서 종종 학습이 오래 걸린다</li>
  <li>데이터 전처리 과정이 복잡하다</li>
  <li>신경망의 중요 매개변수는 <strong>은닉층의 개수</strong>와 <strong>각 은닉층의 유닛 수</strong>
<br /></li>
</ul>

<h1 id="결정-함수">결정 함수</h1>

<p>scikit-learn 분류기에서 불확실성을 추정할 수 있는 함수</p>
<ul>
  <li>decision_function</li>
  <li>predict_proba()
<br /></li>
  <li>이진 분류에서 decision_function의 반환값의 크기는
(n_samples,)이며 각 샘플이 하나의 실수 값을 반환한다</li>
  <li>decision_function 값의 범위는 데이터와 모델 파라미터에 따라 달라진다</li>
</ul>

<blockquote>
  <h3 id="예측-확률">예측 확률</h3>
</blockquote>

<ul>
  <li>predict_proba() 출력은 각 클래스에 대한 확률</li>
  <li>
    <p>이 값의 크기는 이진 분류에서는 항상 (n_samples, 2)</p>
  </li>
  <li>첫 번째 원소 = 첫 번째 클래스의 예측 확률
두 번째 원소 = 두 번째 클래스의 예측 확률</li>
  <li>확률이므로 항상 0과 1 사이의 값이며 합은 항상 1</li>
</ul>

  </article>
  <br>

  <hr/><br>

  <div class="author">
    
    <table>
        <tr>
          <td rowspan="3" style="padding-right: 10px"><img class="author-pic" src="https://github.com/.png" alt=""></td>
          <td><b><h2 rel="author"></h2></b></td>
        </tr>
      <tr>
        <td><p rel="author"></p>
        </td>
      </tr>
      <tr>
        <td>
          <a rel="author" href="https://github.com/" target="_blank"><i class="fa fa-github fa-2x"></i></a>&nbsp&nbsp
          
        </td>
      </tr>
    </table>

  </div>


  <br>
  <hr/>
  <div>
    <script src="https://utteranc.es/client.js"
        repo="gdsc-seoultech/blog-comments"
        issue-term="pathname"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>
  </div>

</div>
<script src="/js/toc.js"></script>
      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper" align="center">
  	<h4>This site was built using <a href="http://jekyllrb.com" target="_blank">Jekyll</a> and is hosted on <a href="https://github.com" target="_blank">Github</a>. &#169; GDSC Seoultech</h4>
  </div>

</footer>


  </body>
</html>
