<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="tYMwPoxNrWfLx2sDrDYzqI4-dq3M3FfI56NBL9JNtH8" />

    <title>4주차 ML 지도학습 WIL</title>
    <meta name="description" content="A simple, whitespace, helvetica based portfolio theme.
">

    <link rel = "shortcut icon" type="image/x-icon" href="/img/square_logo.png">
    <link rel="stylesheet" href="/css/main.css">
<!--    <link rel="canonical" href="http://localhost:4000/posts/1st_term/ml/2021-10-03-ml_wil_ryool/">-->
    <link rel="canonical" href="/posts/1st_term/ml/2021-10-03-ml_wil_ryool/">

    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

    <!-- 카테고리 css -->
    <link rel="stylesheet" href="/css/pagination.css">
    <link href="/css/category.css" type="text/css" rel="stylesheet">
</head>

   
  <body>
    <script src="/js/default.js"></script>
    <header id="tab" >
  <script src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
  <div class="site-header">
    <div class="wrapper">
      <div>
        <a href="/">
          <img src="/img/square_logo.png" align="left" width="57px">
        </a>
      </div>

      <nav class="site-nav">

        <div id="tab" class="trigger">
          <!-- GDSC Seoultech instead of blog -->
          <a class="page-link" href="/">GDSC</a>
          <a class="page-link" href="/members/2">MEMBER</a>
          <a class="page-link" href="/category/2nd_term">POST</a>
        </div>
      </nav>
    </div>
  </div>

  <div id="hovering" class="tab-header">
    <div class="wrapper">
      <div class="detail-post">
          <div class="tab-item">
            <div><a class="page-link-detail" href="/category/1st_term">1기</a></div>
            <div><a class="page-link-detail" href="/category/2nd_term">2기</a></div>
          </div>
      </div>
      <div class="detail-member">
        <div class="tab-item">
          <div><a class="page-link-detail" href="/members/1">1기</a></div>
          <div><a class="page-link-detail" href="/members/2">2기</a></div>
        </div>
    </div>
    </div>

  </div>

  <script type="text/javascript">
    var tabMenu = $("#tab");
    var tabSubMenu = $("#hovering");

    tabSubMenu.hide()

    tabMenu.hover(function() {
      tabSubMenu.show();
    }, function() {
      tabSubMenu.hide();
    })
  </script>

</header>


    <div class="page-content" id="page-content">
      <div class="wrapper" id="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">4주차 ML 지도학습 WIL</h1>
    <h1 class="post-description"></h1>
    <p class="post-meta">October 2, 2021 — 20:00 • seongryool</p>
    
      
        <span class="tag">ml</span>
      
    
  </header>
  <article class="post-content">
    <h1 id="결정트리">결정트리</h1>

<ul>
  <li>
    <p>결정 트리를 학습한다는 것은 정답에 가장 빨리 도달하는 예/아니오 질문 목록을 학습한다는 뜻</p>
  </li>
  <li>
    <p>트리를 만들 때 알고리즘은 가능한 모든 테스트에서 타깃 값에 대해 가장 많은 정보를 가진 것을 고른다.(정보이득, 지니계수, 균일도)</p>
  </li>
  <li>
    <p>데이터를 분할하는 것은 각 분할된 영역이 한 개의 target 값을 가질 때까지 반복된다.
target 하나로만 이뤄진 leaf node를 pure node라고 한다.</p>
  </li>
  <li>
    <p>새로운 데이터 포인트에 대한 예측은 주어진 데이터 포인트가 특성을 분할한 영역들 중 어디에 놓이는지를 확인하면 된다.</p>
  </li>
</ul>

<h3 id="결정트리-복잡도-제어">결정트리 복잡도 제어</h3>

<ul>
  <li>
    <p>보통 tree를 만들 때 모든 leaf 노드가 순수 노드가 될 때까지 진행하면 model이 매우 복잡해지고 훈련 데이터에 overfitting 된다. 즉 pure node로 이뤄진 tree는 훈련 세트에 100% 정확하게 맞는다는 의미이다.</p>
  </li>
  <li>
    <p>overfitting을 막는 전략은 크게 두 가지이다.</p>

    <h3 id="사전-가지치기">사전 가지치기</h3>

    <p>tree 생성을 일찍 중단하는 사전 가지치기 방법<br />
 사전 가지치기는 트리의 최대 깊이나 leat의 최대 개수를 제한하거나 또는 노드가 분할하기 위한 포인트의 최소 개수를 지정하는 것이다.</p>
  </li>
  <li>max_depth : 일정 깊이에 도달하면 트리의 성장을 멈춘다. 깊이를 제한하면 overfitting이 줄어들어 훈련 세트의 정확도를 떨어뜨리지만 테스트 세트의 성능은 개선시킨다.</li>
  <li>max_leaf_nodes :리프 노드의 최대 개수를 지정하는 매개변수</li>
  <li>min_samples_leaf는 리프 노드가 되기 위한 최소한의 샘플 개수</li>
</ul>

<h3 id="사후-가지치기">사후 가지치기</h3>

<p>tree를 만든 후 데이터 포인트가 적은 노드를 삭제하거나 병합하는 전략</p>

<h3 id="트리의-특성-중요도">트리의 특성 중요도</h3>

<ul>
  <li>feature importance를 사용하면 트리를 만든 결정에 각 특성이 얼마나 중요한게 사용되었는지를 알 수 있다.</li>
  <li>이 값은 0과 1 사이의 숫자로, 각 특성에 대해 0은 전혀 사용되지 않았고 1은 완벽하게 타깃 클래스를 예측.</li>
  <li>
    <p>feature importance의 값이 낮다고 해서 유용하지 않다는 뜻은 아니고 단지 트리가 그 특성을 선택하지 않았거나 다른 특성이 동일한 정보를 지니고 있을 수도 있기 때문이다.</p>
  </li>
  <li>
    <h3 id="tree-모델-한계-장단점">tree 모델 한계, 장단점</h3>

    <ul>
      <li>
        <p>tree 모델의 regressor는 모델이 가진 데이터 범위 밖으로 나가면 단순히 마지막 포인트를 이용해 예측을 한다. 즉 트리 모델은 훈련 데이터 밖의 새로운 데이터를 예측할 능력이 없다.</p>
      </li>
      <li>
        <p>결정 트리는 모델을 쉽게 시각화할 수 있기에 이해하기 쉽고 데이터의 스케일에 구애 받지 않는다.</p>
      </li>
    </ul>
  </li>
</ul>

<h1 id="랜덤-포레스트">랜덤 포레스트</h1>

<ul>
  <li>
    <p>앙상블이란 여러 머신러닝 모델을 연결하여 더 강력한 모델을 만드는 기법</p>
  </li>
  <li>
    <p>랜덤 포레스트는 조금씩 다른 여러 결정 트리의 묶음이다. 즉 여러 트리 모델을 만들고 그 결과를 평균내어서 사용한다.</p>
  </li>
  <li>
    <p>랜덤 포레스트에서 tree를 랜덤하게 만드는 방법은 두 가지. 1. 데이터 포인트를 무작위로 선택 2. 분할 테스트에서 특성을 무작위로 선택</p>
  </li>
  <li>
    <p>부트스트랩 샘플이용 : n_samples개의 데이터 포인트중에서 무작위로 데이터를 n_samples 횟수만큼 반복 추출한다.</p>
  </li>
</ul>

<h3 id="랜덤-포레스트-장단점">랜덤 포레스트 장단점</h3>

<ul>
  <li>단일 트리의 단점을 보완하고 장점은 그대로 가지고 잇다.</li>
  <li>수 백개의 트리를 자세히 분석하기는 어렵고 랜덤 포레스트의 트리는 결정 트리보다 더 깊어지는 경향도 있다.</li>
  <li>텍스트 데이터 같이 매우 차원이 높고 희소한 데이터에는 잘 작동하지 않는다.</li>
  <li>선형 모델보다 많은 메모리를 사용하며 훈련과 예측이 느리다.</li>
</ul>

<h1 id="그레이디언트-부스팅-회귀-트리">그레이디언트 부스팅 회귀 트리</h1>

<ul>
  <li>여러 개의 결정 트리를 묶어 모델을 만드는 앙상블 방법, 이름이 회귀지만 회귀와 분류에 모두 사용 가능</li>
  <li>이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만든다. 이게 부스팅 방식</li>
  <li>무작성이 없고 강력한 사전 가지치기 사용</li>
  <li>learning_rate : 이전 트리의 오차를 얼마나 강하게 보정할 것인지 제어</li>
  <li>단점 : 매겨변수를 잘 조정해야하고 훈련 시간이 길다.</li>
  <li>장점 : 다른 트리 기반 모델처럼 특성의 스케일을 조정하지 않아도 되고 이진 특성이나 연속적인 특성에서도 잘 동작한다.</li>
  <li>모델의 특성상 희소한 고차원 데이터에는 잘 작동하지 않는다.</li>
  <li>n_estimators를 크게 하면 모델이 복잡해지고 과대적합될 가능성이 높아진다.</li>
  <li>보통 max_depth를 매우 작게 설정하고 트리의 깊이가 5보다 깊어지지 않게 한다.</li>
</ul>

<h1 id="커널-서포트-벡터-머신-svm">커널 서포트 벡터 머신 SVM</h1>

<ul>
  <li>SVM은 입력 데이터에서 단순한 초평면으로 정의되지 않는 더 복잡한 모델을 만들 수 있도록 확장한 것</li>
  <li>선형 모델을 유연하게 만들려면 특성끼리 곱하거나 특성을 거듭제곱하는 식으로 새로운 특성을 추가.</li>
  <li>
    <p>커널 기법 : 데이터를 확장하지 않고 확장된 특성에 대한 데이터 포인트들의 거리를 계산한다.</p>

    <ul>
      <li>원래의 특성의 가능한 조합을 지정된 차수까지 계산</li>
      <li>가우시안 커널로 불리는 RBF 커널 : 차원이 무한한 특성 공간에 매핑하는 것으로 모든 차수의 모든 다항식을 고려한다고 생각하면 됨. 특성의 중요도는 고차항이 될수록 줄어든다.</li>
    </ul>
  </li>
  <li>서포트 벡터 : 두 클래스 사이의 경계에 위치한 데이터 포인트
    <ul>
      <li>새로운 데이터 포인트에 대해 예측하려면 서포트 벡터와의 거리 측정</li>
    </ul>
  </li>
  <li>
    <p>gamma : 가우시안 커널 폭의 역수, 하나의 훈련 샘플이 미치는 영향의 범위 결정</p>

    <ul>
      <li>작은 값은 넓은 영역, 큰 값은 좁은 영역</li>
      <li>가우시안 커널의 반경이 클 수록 훈련 샘플의 영향 범위도 커짐</li>
    </ul>
  </li>
  <li>C : 규제 매개변수, 각 포인트의 중요도를 제한한다.</li>
  <li>SVM에서의 데이터 전처리는 특성 값을 평균 0, 단위 분산 or 0과 1 사이로 맞추는 방법 많이 사용</li>
  <li>다양한 데이터셋에서 잘 작동, 데이터의 특성이 몇 개 없어도 복잡한 결정 경계 만들 수 있다.</li>
  <li>특성이 적을 때와 많을 때에 모두 잘 작동하지만 샘플이 많을 때는 잘 맞지 않는다.</li>
  <li>단점으론 데이터 전처리와 매개변수 설정에 신경을 많이 써야한다.</li>
  <li>모든 특성이 비슷한 단위고 스케일이 비슷하면 SVM을 시도할만 하다.</li>
</ul>

<h1 id="신경망">신경망</h1>

<ul>
  <li>다층 퍼셉트론(MultiLayer Perpeptros,MLP)</li>
  <li>가중치 합을 만드는 과정이 여러 번 반복되고, 먼저 중간 단계를 구성하는 hidden unity 계산 후 이를 이용하여 최종 결과를 산출하기 위해 다시 가중치 합을 계산.</li>
  <li>각 은닉 유닛의 가중치 합을 계산한 후 그 결과에 비선형 함수인 ReLU, tanh를 적용</li>
  <li>은닉층으로 구성된 대규모의 신경망이 생기면서 딥러닝이라고 부름</li>
  <li>alpha : 패널티를 의미, 모델의 복잡도 제어, alpha 작으면 가중치 커짐</li>
  <li>가중치를 무작위로 설정하는 것이 모델 학습에 영향을 끼침</li>
  <li>MLP 또한 데이터 스케일에 영향을 많이 받음</li>
  <li>대량의 데이터에 내재된 정보를 잡아내고 매우 복잡한 모델을 만들 수 있다는 점</li>
  <li>학습 시간이 오래 걸리고 데이터 전처리에 주의</li>
  <li>SVM과 비슷하게 모든 특성이 같은 의미를 가진 데이터에서 잘 작동</li>
  <li>다른 종류의 특성을 가진 데이터면 트리 기반의 모델이 잘 작동할 수 있다.</li>
</ul>

<h1 id="정리">정리</h1>

<ul>
  <li>KNN : 작은 데이터셋일 경우, 기본 모델로 좋고 설명하기 쉽다.</li>
  <li>선형 모델 : 대용량 데이터셋 가능, 고차원 데이터에 가능</li>
  <li>나이브 베이즈 : 분류만 가능, 데용량 데이텃과 고차원 데이터 가능</li>
  <li>결정 트리 : 매우 빠름, 스케일 조정 필요 없다.</li>
  <li>랜덤 포레스트 : 안정적이고 강력함. 데이터 스케일 조정 필요 없음, 고차원 희소 데이터에는 잘 안 맞음</li>
  <li>그레이디언트 부스터 결정트리 : 랜포보다 좀 더 성능이 좋음, 학습은 느리나 예측은 빠르고 메모리를 조금 사용, 매개변수 튜닝 많이 필요</li>
  <li>서포트 벡터 머신 : 비슷한 의미의 특성으로 이뤄진 중간 규모 데이터셋에 잘 맞음. 데이터 스케일 조정 필요, 매개변수에 민감</li>
  <li>신경망 : 대용량 데이터셋에서 매우 복잡한 모델을 만들 수 있음. 매개변수 선택과 데이터 스케일에 민감. 큰 모델은 학습이 오래 걸림</li>
</ul>

  </article>
  <br>

  <hr/><br>

  <div class="author">
    
    <table>
        <tr>
          <td rowspan="3" style="padding-right: 10px"><img class="author-pic" src="https://github.com/.png" alt=""></td>
          <td><b><h2 rel="author"></h2></b></td>
        </tr>
      <tr>
        <td><p rel="author"></p>
        </td>
      </tr>
      <tr>
        <td>
          <a rel="author" href="https://github.com/" target="_blank"><i class="fa fa-github fa-2x"></i></a>&nbsp&nbsp
          
        </td>
      </tr>
    </table>

  </div>


  <br>
  <hr/>
  <div>
    <script src="https://utteranc.es/client.js"
        repo="gdsc-seoultech/blog-comments"
        issue-term="pathname"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>
  </div>

</div>
<script src="/js/toc.js"></script>
      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper" align="center">
  	<h4>This site was built using <a href="http://jekyllrb.com" target="_blank">Jekyll</a> and is hosted on <a href="https://github.com" target="_blank">Github</a>. &#169; GDSC Seoultech</h4>
  </div>

</footer>


  </body>
</html>
