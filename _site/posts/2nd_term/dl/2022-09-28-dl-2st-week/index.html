<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="tYMwPoxNrWfLx2sDrDYzqI4-dq3M3FfI56NBL9JNtH8" />

    <title>딥러닝 2주차 - 데이터의 기본과 텐서</title>
    <meta name="description" content="A simple, whitespace, helvetica based portfolio theme.
">

    <link rel = "shortcut icon" type="image/x-icon" href="/img/square_logo.png">
    <link rel="stylesheet" href="/css/main.css">
<!--    <link rel="canonical" href="http://localhost:4000/posts/2nd_term/dl/2022-09-28-dl-2st-week/">-->
    <link rel="canonical" href="/posts/2nd_term/dl/2022-09-28-dl-2st-week/">

    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

    <!-- 카테고리 css -->
    <link rel="stylesheet" href="/css/pagination.css">
    <link href="/css/category.css" type="text/css" rel="stylesheet">
</head>

   
  <body>
    <script src="/js/default.js"></script>
    <header id="tab" >
  <script src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
  <div class="site-header">
    <div class="wrapper">
      <div>
        <a href="/">
          <img src="/img/square_logo.png" align="left" width="57px">
        </a>
      </div>

      <nav class="site-nav">

        <div id="tab" class="trigger">
          <!-- GDSC Seoultech instead of blog -->
          <a class="page-link" href="/">GDSC</a>
          <a class="page-link" href="/members/2">MEMBER</a>
          <a class="page-link" href="/category/2nd_term">POST</a>
        </div>
      </nav>
    </div>
  </div>

  <div id="hovering" class="tab-header">
    <div class="wrapper">
      <div class="detail-post">
          <div class="tab-item">
            <div><a class="page-link-detail" href="/category/1st_term">1기</a></div>
            <div><a class="page-link-detail" href="/category/2nd_term">2기</a></div>
          </div>
      </div>
      <div class="detail-member">
        <div class="tab-item">
          <div><a class="page-link-detail" href="/members/1">1기</a></div>
          <div><a class="page-link-detail" href="/members/2">2기</a></div>
        </div>
    </div>
    </div>

  </div>

  <script type="text/javascript">
    var tabMenu = $("#tab");
    var tabSubMenu = $("#hovering");

    tabSubMenu.hide()

    tabMenu.hover(function() {
      tabSubMenu.show();
    }, function() {
      tabSubMenu.hide();
    })
  </script>

</header>


    <div class="page-content" id="page-content">
      <div class="wrapper" id="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">딥러닝 2주차 - 데이터의 기본과 텐서</h1>
    <h1 class="post-description"></h1>
    <p class="post-meta">September 28, 2022 — 09:00 • keonju</p>
    
      
        <span class="tag">dl</span>
      
    
  </header>
  <article class="post-content">
    <h1 id="2주차는-무엇을-배웠나요">2주차는 무엇을 배웠나요</h1>

<ol>
  <li>Tensor 만들기</li>
  <li>Tensor 바꾸기</li>
  <li>Tensor 연산하기</li>
  <li>DataFrame을 Tensor로 만들기</li>
  <li>실습</li>
  <li>마치며</li>
</ol>

<p>에 대해서 알아보았습니다! <br />
지난주에 배웠던 Numpy와 비슷한 Tensor이지만 더 많은 내용을 다뤘습니다!<br />
내용이 많이 늘어나 많이 힘들었지만 다들 열십히 참여해주셨습니다..! (분량 조절 실패한 사람 반성중.. 🥺)<br />
이번에도 중간중간 과제로 더 공부한 내용들도 있으니 참고해주세요!</p>

<p>함께 기본 데이터 구조인 텐서를 시작으로 본격적으로 딥러닝 기초를 다져보아요!!</p>

<p><br /> 
<br /> 
<br /></p>

<hr />

<h2 id="1-tensor-만들기">1. Tensor 만들기</h2>
<p>Tensor를 만들고 Tensor의 요소들을 확인하는 방법을 먼저 알아보았습니다.</p>

<p><br /> 
<br /></p>

<h3 id="tensor-생성">Tensor 생성</h3>
<ul>
  <li>arange : 같은 간격의 1차원 텐서</li>
  <li>zeros : 0으로 이루어진 텐서</li>
  <li>ones : 1로 이루어진 텐서</li>
  <li>randn : 0~1의 값으로 이루어진 텐서</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[[1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.]],

        [[1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.]]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[-1.4006,  0.6990, -0.3430, -0.4306],
        [ 1.2131, -0.1662, -0.8585,  0.0919],
        [ 1.5555, -1.7267, -1.5563,  0.0836]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[2, 1, 4, 3],
        [1, 2, 3, 4],
        [4, 3, 2, 1]])
</code></pre></div></div>

<h3 id="tensor-형태-파악하기">Tensor 형태 파악하기</h3>

<ul>
  <li>numel : element 수 파악</li>
  <li>shape : Tensor 형태 파악</li>
  <li>dtype : 데이터 타입 파악</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="n">numel</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([12])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="n">dtype</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.float32
</code></pre></div></div>

<h3 id="준석--tensor의-타입을-알려주세요">준석 ) Tensor의 타입을 알려주세요.</h3>

<p>torch.Tensor()의 기본 텐서 타입은 torch.FloatTensor 이다.</p>

<p>텐서 타입은 초기화 할 때 지정하거나 나중에 다른 타입으로 변경할 수 있다.</p>
<ul>
  <li>초기화 시 타입 지정<br />
1) FloatTensor 같은 특정 텐서 타입의 생성자를 직접 호출 또는 타입 캐스팅 메소드 사용<br />
2) torch.Tensor()와 함께 dtype 매개변수를 사용</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">describe</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"타입: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nb">type</span><span class="p">()))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"값: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># float형
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>타입: torch.FloatTensor
값: tensor([[1., 2., 3.],
        [4., 5., 6.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># long형
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>타입: torch.LongTensor
값: tensor([[1, 2, 3],
        [4, 5, 6]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ShortTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># short형
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>타입: torch.ShortTensor
값: tensor([[1, 2, 3],
        [4, 5, 6]], dtype=torch.int16)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">double</span><span class="p">()</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 타입 캐스팅 메소드
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>타입: torch.DoubleTensor
값: tensor([[1., 2., 3.],
        [4., 5., 6.]], dtype=torch.float64)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nb">int</span><span class="p">()</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 타입 캐스팅 메소드
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>타입: torch.IntTensor
값: tensor([[1, 2, 3],
        [4, 5, 6]], dtype=torch.int32)
</code></pre></div></div>

<h4 id="여기까지는-앞서-언급했던-첫-번째-방식으로-tensor의-타입을-지정했다">여기까지는 앞서 언급했던 첫 번째 방식으로 tensor의 타입을 지정했다</h4>
<ul>
  <li>FloatTensor 같은 특정 텐서 타입의 생성자를 직접 호출 또는 타입 캐스팅 메소드 사용</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>타입: torch.DoubleTensor
값: tensor([[1., 2., 3.],
        [4., 5., 6.],
        [7., 8., 9.]], dtype=torch.float64)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>타입: torch.LongTensor
값: tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]])
</code></pre></div></div>

<h4 id="여기까지는-두-번쨰-방식을-이용했다">여기까지는 두 번쨰 방식을 이용했다.</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># shape 또는 size()를 통해 텐서의 크기를 확인할 수 있다.
</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([3, 3])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span><span class="p">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([3, 3])
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/54880474/192807948-44620bd9-6991-476e-adfe-55a6dd7464af.png" alt="20220928_233616" /></p>

<h5 id="다음과-같이-각-데이터형-별로-데이터-타입이-정해져있는-것을-알-수-있다">다음과 같이 각 데이터형 별로 데이터 타입이 정해져있는 것을 알 수 있다.</h5>

<h3 id="인덱싱과-슬라이싱">인덱싱과 슬라이싱</h3>

<p>넘파이 같은 방식으로 인덱싱과 슬라이싱, 값도 변환할 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(11.)
tensor([1., 2.])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">17</span>
<span class="n">x</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([ 0., 17.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">x</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([12., 12.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])
</code></pre></div></div>

<p><br />
<br />
<br />
—</p>

<h2 id="2-tensor-바꾸기">2. Tensor 바꾸기</h2>
<p>Tensor 형태를 변환하고 Tensor을 합치고, 나누는 방법을 알아보았습니다.<br />
<br /></p>

<h3 id="tensor-형태-변환">Tensor 형태 변환</h3>
<ul>
  <li>reshape : contiguous하지 않을 때도 변환 가능!</li>
  <li>view : contiguous하지 않으면 변환 불가능!</li>
  <li>squeeze : 1인 차원 제거</li>
  <li>unsqueeze : 1인 차원 추가</li>
  <li>transpose : 전치 행렬</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">X</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[12., 12.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
               <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span>
              <span class="p">[[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
               <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]]])</span>
<span class="n">ft</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([2, 2, 3])
</code></pre></div></div>

<p>-1은 다른 차원으로부터 맞춰서 변환됩니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]).</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[ 0.,  1.,  2.],
        [ 3.,  4.,  5.],
        [ 6.,  7.,  8.],
        [ 9., 10., 11.]])
torch.Size([4, 3])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]).</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[[ 0.,  1.,  2.]],

        [[ 3.,  4.,  5.]],

        [[ 6.,  7.,  8.]],

        [[ 9., 10., 11.]]])
torch.Size([4, 1, 3])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ft</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0.],
        [1.],
        [2.]])
torch.Size([3, 1])
</code></pre></div></div>

<p>squeeze를 통해 2차원에서 1차원으로 변형되었습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">squeeze</span><span class="p">().</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([0., 1., 2.])
torch.Size([3])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ft</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([3])
</code></pre></div></div>

<p>다시 unsqueeze를 통해 2차원으로 변경되었습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0., 1., 2.]])
torch.Size([1, 3])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0., 1., 2.]])
torch.Size([1, 3])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0.],
        [1.],
        [2.]])
torch.Size([3, 1])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">ft</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0.],
        [1.],
        [2.]])
torch.Size([3, 1])
</code></pre></div></div>

<p>Transpose는 행과 열을 바꿔주는 방법입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">A</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0, 1],
        [2, 3],
        [4, 5]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span><span class="p">.</span><span class="n">T</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0, 2, 4],
        [1, 3, 5]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="n">A</span> <span class="o">==</span> <span class="n">A</span><span class="p">.</span><span class="n">T</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[True, True, True],
        [True, True, True],
        [True, True, True]])
</code></pre></div></div>

<h3 id="혁--contiguous에-대해-알려주세요">혁 ) contiguous()에 대해 알려주세요.</h3>

<p>contiguous()는 텐서를 numpy같은 방식으로 메모리에 저장하는 방식을 말합니다.<br />
numpy는 인접한 배열의 데이터는 인접한 메모리에 저장함으로써 접근속도나 transpose속도가 매우 빠르게됩니다.<br />
보통 view(),narrow(),expand(),tranpose()를 써서 텐서모양을 고칠때 contiguous형식이 요구되는데<br />
예를 들어 view()같은 경우는 reshape나 resize와는 다르게 어떤 경우에도 메모리 복사없이 이루어집니다.<br />
따라서 contiguous형식이 아닐때는 텐서모양을 고칠수 없게되고 런타임에러가 발생합니다.</p>

<p>코드를 통해서 contiguous에 대해 설명하겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">is_contiguous</span><span class="p">())</span>
<span class="n">a</span><span class="p">.</span><span class="n">transpose_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">is_contiguous</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>True
tensor([[ 1.0009,  0.1026, -1.1214],
        [ 0.7532,  2.0344,  1.4519],
        [-0.5742, -1.3162,  1.5134],
        [ 1.2349, -1.2356,  1.7235]])
True
tensor([[-0.2183,  2.2920, -0.2232],
        [ 0.0463, -0.4723,  0.8091],
        [-0.7852,  1.6145, -0.2895],
        [ 0.5062,  0.6791,  1.3657]])
</code></pre></div></div>

<p>랜덤으로 a와 b라는 Tensor를 만들었습니다.<br />
a와 b는 형성되어졌을 때, is_contiguous를 통해서 두 Tensor 모두 contiguous한 것을 알 수 있습니다.<br />
그럼 아래의 코드를 통해 tranpose 이후 a와 b의 차이를 보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">data_ptr</span><span class="p">())</span>
  
<span class="k">print</span><span class="p">(</span><span class="s">'*'</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">data_ptr</span><span class="p">())</span>    
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1863763599552
1863763599568
1863763599584
1863763599556
1863763599572
1863763599588
1863763599560
1863763599576
1863763599592
1863763599564
1863763599580
1863763599596
**********
1863763604288
1863763604292
1863763604296
1863763604300
1863763604304
1863763604308
1863763604312
1863763604316
1863763604320
1863763604324
1863763604328
1863763604332
</code></pre></div></div>

<p>각 텐서 요소의 주소를 추출하였습니다.<br />
각 데이터 타입인 torch.float32 자료형은 4바이트 이므로,<br />
메모리 1칸 당 주소 값이 4씩 증가하는 것을 볼 수 있습니다.<br />
b는 한 줄에 4씩 값이 증가하지만 a는 그렇지 않은 것을 확인할 수 있습니다.<br />
아래코드를 보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">stride</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">stride</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">is_contiguous</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">is_contiguous</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1, 4)
(3, 1)
False
True
</code></pre></div></div>

<p>a가 tranpose된 이후에 false로 바뀐 것을 알 수 있습니다.<br />
즉 b는 오른쪽 방향으로 자료가 순서대로 저장됨에 비해<br />
a는 tranpose 연산을 거치며 axis = 1인 아래 방향으로 자료가 저장되고 있습니다.<br />
stride메소드를 보면, 데이터의 저장 방향을 알 수 있습니다.<br />
a의 stride 결과값을 해석하자면<br />
a[0][0]-&gt;a[1][0]으로 증가할 때는 자료 1개 만큼 메모리 주소가 이동되고,<br />
a[0][0]-&gt;a[0][1]으로 증가할 때는 자료 4개 만큼의 메모리 주소가 바뀐다는 의미입니다.<br />
그래서 a의 for문 결과의 처음 3줄에는 메모리가 16씩 증가하는 것을 확인할 수 있습니다.</p>

<p>현재 tranpose 된 a 같은 경우는 contiguous는 False로 자료를 순서대로 저장하고 있지 않습니다.<br />
이상태에서 reshape,resize가 아닌 view를 써보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">is_contiguous</span><span class="p">())</span>
<span class="n">a</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>False



---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)

~\AppData\Local\Temp/ipykernel_26164/2291854614.py in &lt;module&gt;
      1 print(a.is_contiguous())
----&gt; 2 a.view(2,6)


RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
</code></pre></div></div>

<p>이렇게 RuntimeError가 발생하는 것을 확인할 수 있습니다.</p>

<p>그럼 a가 view를 사용할 수 있도록 contiguous()를 통해서 바꾸어보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="n">contiguous</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">is_contiguous</span><span class="p">())</span>
<span class="n">a</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>True





tensor([[ 1.0009,  0.1026, -1.1214,  0.7532,  2.0344,  1.4519],
        [-0.5742, -1.3162,  1.5134,  1.2349, -1.2356,  1.7235]])
</code></pre></div></div>

<p>현재는 a가 contigious True 형태로 바뀌었고 view가 적용되는 모습을 확인할 수 있습니다.</p>

<p>감사합니다.</p>

<h3 id="tensor-합치기-나누기">Tensor 합치기, 나누기</h3>

<ul>
  <li>cat, stacking : 텐서를 합칩니다.</li>
  <li>chunk, split : 텐서를 나눠줍니다.</li>
</ul>

<p><br /></p>

<h4 id="tensor-합치기">Tensor 합치기</h4>
<p>dim을 통해 합쳐줄 축을 정해줍니다.</p>

<p>cat은 주어진 차원을 기준으로, stack은 새로운 차원으로 주어진 텐서를 붙입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1., 2.],
        [3., 4.],
        [5., 6.],
        [7., 8.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1., 2., 5., 6.],
        [3., 4., 7., 8.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[[1., 2.],
         [3., 4.]],

        [[5., 6.],
         [7., 8.]]])
</code></pre></div></div>

<p>cat은 (4,2)의 크기를, stack은 (2,2,2)의 크기를 갖는 것을 알수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1., 4.],
        [2., 5.],
        [3., 6.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">z</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1., 4.],
        [2., 5.],
        [3., 6.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1., 2., 3.],
        [4., 5., 6.]])
</code></pre></div></div>

<h4 id="tensor-나누기">Tensor 나누기</h4>

<p>chunk는 n개의 그룹을 만들고, split은 n개의 데이터가 있는 그룹을 만듭니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 3개의 그룹을 만드는 chunk
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

<span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">t3</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">t1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">t2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">t3</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0.3124, 0.3670, 0.4461, 0.3799, 0.4759, 0.7645],
        [0.9245, 0.2099, 0.4981, 0.2253, 0.1432, 0.4176],
        [0.3214, 0.4409, 0.4165, 0.0611, 0.4758, 0.6666]])
tensor([[0.3124, 0.3670],
        [0.9245, 0.2099],
        [0.3214, 0.4409]])
tensor([[0.4461, 0.3799],
        [0.4981, 0.2253],
        [0.4165, 0.0611]])
tensor([[0.4759, 0.7645],
        [0.1432, 0.4176],
        [0.4758, 0.6666]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 3개의 데이터가 있는 그룹을 만드는 split (2개의 tensor로 분리)
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

<span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">t1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">t2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0.5875, 0.2308, 0.4805, 0.2589, 0.5313, 0.8857],
        [0.9570, 0.9571, 0.2845, 0.7530, 0.4334, 0.5157],
        [0.6430, 0.3617, 0.3446, 0.9501, 0.4462, 0.8290]])
tensor([[0.5875, 0.2308, 0.4805],
        [0.9570, 0.9571, 0.2845],
        [0.6430, 0.3617, 0.3446]])
tensor([[0.2589, 0.5313, 0.8857],
        [0.7530, 0.4334, 0.5157],
        [0.9501, 0.4462, 0.8290]])
</code></pre></div></div>

<p><br />
<br />
<br /></p>

<hr />

<h2 id="3-tensor-연산하기">3. Tensor 연산하기</h2>

<p>Tensor 값들끼리의 연산, Tensor간의 연산을 알아보았습니다.</p>

<p><br /></p>

<h3 id="기본-연산">기본 연산</h3>
<ul>
  <li>+, -, *, / : 같은 위치끼리 연산</li>
  <li>sum, cumsum : 합과 누적합</li>
  <li>mean, std : 통계값</li>
  <li>exp : 지수합수</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">/</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">**</span> <span class="n">y</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensor([ 3.,  4.,  6., 10.]),
 tensor([-1.,  0.,  2.,  6.]),
 tensor([ 2.,  4.,  8., 16.]),
 tensor([0.5000, 1.0000, 2.0000, 4.0000]),
 tensor([ 1.,  4., 16., 64.]))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">==</span> <span class="n">y</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([False,  True, False, False])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(15.)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1.6275e+05, 1.6275e+05, 7.3891e+00, 2.0086e+01],
        [5.4598e+01, 1.4841e+02, 4.0343e+02, 1.0966e+03],
        [2.9810e+03, 8.1031e+03, 2.2026e+04, 5.9874e+04]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1, 2, 3],
        [2, 0, 4],
        [3, 4, 5]])
</code></pre></div></div>

<p>axis를 통해 연산해줄 행, 열을 지정해줍니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">A</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(torch.Size([3, 3]), tensor([ 6,  6, 12]))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">A</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(torch.Size([3, 3]), tensor([ 6,  6, 12]))
</code></pre></div></div>

<p>keepdims를 통해 차원을 유지하며 연산할 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sum_A</span> <span class="o">=</span> <span class="n">A</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sum_A</span><span class="p">,</span> <span class="n">sum_A</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensor([[ 6],
         [ 6],
         [12]]), torch.Size([3, 1]))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">/</span> <span class="n">sum_A</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0.1667, 0.3333, 0.5000],
        [0.3333, 0.0000, 0.6667],
        [0.2500, 0.3333, 0.4167]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span><span class="p">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[ 1,  2,  3],
        [ 3,  2,  7],
        [ 6,  6, 12]])
</code></pre></div></div>

<h3 id="정준--in-place-연산에-대해-알려주세요">정준 ) in-place 연산에 대해 알려주세요</h3>

<p>우선 2X2형태의 텐서를 만들어 변수 x에 저장합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
</code></pre></div></div>

<p>곱하기 연산을 한 값과 기존의 값을 출력하면?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">mul</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span> <span class="c1"># 곱하기 2를 수행한 결과를 출력
</span><span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 기존의 값 출력
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    tensor([[2., 4.],
            [6., 8.]])
    tensor([[1., 2.],
            [3., 4.]])
</code></pre></div></div>

<p>첫번째 출력은 곱하기 2가 수행된 결과를 보여주고, 두번째 출력은 기존의 값이 그대로 출력된 것을 확인할 수 있습니다.<br />
곱하기 2를 수행했지만 이를 x에다가 다시 저장하지 않았으니, 곱하기 연산을 하더라도 기존의 값 x는 변하지 않는 것이 당연합니다.</p>

<p>그런데 연산 뒤에 _를 붙이면 어떻게 될까요? 기존의 값을 덮어쓰기 합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">mul_</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span>  <span class="c1"># 곱하기 2를 수행한 결과를 변수 x에 값을 저장하면서 결과를 출력
</span><span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 기존의 값 출력
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    tensor([[2., 4.],
            [6., 8.]])
    tensor([[2., 4.],
            [6., 8.]])
</code></pre></div></div>

<p>이렇듯 x의 값이 덮어 씌워져서 2 곱하기 연산이 된 결과가 출력됩니다.<br />
in-place 연산(연산 뒤에 _붙이기)을 사용하면 새로운 변수를 지정하지 않아도 기존 변수의 값이 바뀝니다.</p>

<p>이렇듯 값을 자주 업데이트 해 줘야 할 때 in-place 연산을 사용한다면 편리합니다.<br />
예로 들어, 선형 회귀 구현 시 w와 b의 값들을 업데이트할 때, <br />
in-place 연산을 써주게 된다면, 새로운 변수를 사용하는 것보다 속도도 빠르고 코드도 간편해진다는 장점이 있습니다.</p>

<p>한가지 예시를 더 들어보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="n">a</span><span class="p">.</span><span class="n">add_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    tensor([1., 1., 1., 1., 1.])
    [1. 1. 1. 1. 1.]
    tensor([2., 2., 2., 2., 2.])
    [2. 2. 2. 2. 2.]
</code></pre></div></div>

<h3 id="선형대수학">선형대수학</h3>
<p>선형대수학에서 사용하는 연산들을 공부했습니다</p>

<ul>
  <li>dot : dot product</li>
  <li>mv, @ : Matrix - Vector product</li>
  <li>mm, @ : Matrix - Matrix product</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">mv</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">A</span><span class="o">@</span><span class="n">x</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(torch.Size([2, 3]), torch.Size([3]), tensor([ 5., 14.]), tensor([ 5., 14.]))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">mm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">))</span> 
<span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">@</span><span class="n">B</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[ 3.,  3.,  3.,  3.],
        [12., 12., 12., 12.]])
tensor([[ 3.,  3.,  3.,  3.],
        [12., 12., 12., 12.]])
</code></pre></div></div>

<h4 id="norm">Norm</h4>

<p>벡터의 크기 또는 길이를 측정하는 Norm을 공부하였습니다.<br />
L1 Norm과 L2 Norm의 식도 간단하게 알아보았습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="p">])</span>
<span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="c1"># L2 Norm
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(5.)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">u</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span> <span class="c1"># L1 Norm
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(7.)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(6.)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(3.7417)
</code></pre></div></div>

<h4 id="autograd">Autograd</h4>

<p>autograd는 파이토치의 자동 미분 엔진입니다. <br />
미분값(gradient)을 수집하고 저장해줍니다.</p>
<ul>
  <li>requires_grad : 연산 추적 여부를 선택할 수 있습니다.</li>
  <li>backward : 역전파 시작</li>
  <li>grad.zero : 기울기 초기화</li>
  <li>x.grad : 저장된 기울기 반환</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="n">x</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([0., 1., 2., 3.])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">x</span><span class="p">.</span><span class="n">grad</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">y</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(28., grad_fn=&lt;MulBackward0&gt;)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="p">.</span><span class="n">grad</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([ 0.,  4.,  8., 12.])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="n">grad</span> <span class="o">==</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">x</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([True, True, True, True])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>  <span class="c1"># Reset the gradient
</span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
<span class="n">y</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="p">.</span><span class="n">grad</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([1., 1., 1., 1.])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">y</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">gradient</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>  <span class="c1"># Faster: y.sum().backward()
</span><span class="n">x</span><span class="p">.</span><span class="n">grad</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([0., 2., 4., 6.])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">detach</span><span class="p">()</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">u</span> <span class="o">*</span> <span class="n">x</span>

<span class="n">z</span><span class="p">.</span><span class="nb">sum</span><span class="p">().</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="p">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">u</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([True, True, True, True])
</code></pre></div></div>

<h3 id="연수--detach-clone-에-대해-알려주세요">연수 ) detach(), clone() 에 대해 알려주세요.</h3>

<h4 id="tensor를-복사하는-방법">Tensor를 복사하는 방법</h4>

<h5 id="1-detach--기존-tensor에서-gradient-전파가-안되는-텐서-생성">1. detach() : 기존 Tensor에서 gradient 전파가 안되는 텐서 생성</h5>
<h5 id="2-clone---기존-tensor와-내용을-복사한-텐서-생성">2. clone() :  기존 Tensor와 내용을 복사한 텐서 생성</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">a</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([-0.0803, -0.1637, -0.0640, -0.4010, -0.9398])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="n">detach</span><span class="p">()</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="n">clone</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([-0.0803, -0.1637, -0.0640, -0.4010, -0.9398]) tensor([-0.0803, -0.1637, -0.0640, -0.4010, -0.9398])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([ 1.0000, -0.1637, -0.0640, -0.4010, -0.9398])
</code></pre></div></div>

<p>b를 변경하자 a도 변한것을 알 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([ 2.0000, -0.1637, -0.0640, -0.4010, -0.9398]) tensor([ 1.0000, -0.1637, -0.0640, -0.4010, -0.9398])
</code></pre></div></div>

<p>clone()한 tensor는 값이 변경되어도 원래 tensor 값이 변하지 않는다</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<p><br />
<br />
<br /></p>

<hr />

<h2 id="4-dataframe을-tensor로-만들기">4. DataFrame을 Tensor로 만들기</h2>

<p>torch.tensor을 통해 데이터프레임 형태도 Tensor로 만들어줄 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="p">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">'..'</span><span class="p">,</span> <span class="s">'data'</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data_file</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">'..'</span><span class="p">,</span> <span class="s">'data'</span><span class="p">,</span> <span class="s">'house_tiny.csv'</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">'''NumRooms,RoofType,Price
NA,NA,127500
2,NA,106000
4,Slate,178100
NA,NA,140000'''</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   NumRooms RoofType   Price
0       NaN      NaN  127500
1       2.0      NaN  106000
2       4.0    Slate  178100
3       NaN      NaN  140000
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">dummy_na</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   NumRooms  RoofType_Slate  RoofType_nan
0       NaN               0             1
1       2.0               0             1
2       4.0               1             0
3       NaN               0             1
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   NumRooms  RoofType_Slate  RoofType_nan
0       3.0               0             1
1       2.0               0             1
2       4.0               1             0
3       3.0               0             1
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">values</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">targets</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensor([[3., 0., 1.],
         [2., 0., 1.],
         [4., 1., 0.],
         [3., 0., 1.]], dtype=torch.float64),
 tensor([127500, 106000, 178100, 140000]))
</code></pre></div></div>

<h3 id="재영--array---tensor-간-변환-방법을-알려주세요">재영 ) Array - Tensor 간 변환 방법을 알려주세요.</h3>

<p>Pytorch에서 numpy array를 Tensor 자료형으로 바꾸기 위해서는 <code class="language-plaintext highlighter-rouge">torch.Tensor()</code>와 <code class="language-plaintext highlighter-rouge">torch.from_numpy()</code>를 활용할 수 있습니다.</p>

<p>먼저, <code class="language-plaintext highlighter-rouge">torch.Tensor()</code> 를 <a href="https://pytorch.org/docs/stable/tensors.html">pytorch 공식 문서</a>에서 확인해본다면 말그대로 Tensor를 만들어내는 구문이기 때문에 나와 있는 예시에는 array가 직접 들어가 있는 경우를 많이 확인할 수 있습니다.</p>

<p>그리고 아래와 같이 생성되는 Tensor의 데이터 타입마다 어떠한 구문을 써야하는지 나타나 있습니다. 아래의 이미지는 그 중 일부를 발췌한 것입니다.</p>

<div align="center"> <img src="https://drive.google.com/uc?id=14E34d4n2UhkkVNlCL0EanexuC8gS_hyL" /> </div>

<p>또한, <code class="language-plaintext highlighter-rouge">torch.from_numpy()</code> 를 <a href="&quot;https://pytorch.org/docs/stable/generated/torch.from_numpy.html&quot;">pytorch 공식 문서</a>에서 확인해본다면 <code class="language-plaintext highlighter-rouge">Creates a Tensor from a numpy.ndarray</code> 라고 설명되어 있는 것을 확인할 수 있습니다. 말 그대로 numpy로 만들어진 array를 tensor로 만들어주는 역할을 하게 됩니다.</p>

<div align="center"> <img src="https://drive.google.com/uc?id=1DGSJhwGKGAkVUm478YmIRP25nhycTbHj" /> </div>

<p>다만, 주의해야할 점은 만들어진 tensor는 기존의 ndarray와 동일한 메모리를 공유한다는 점입니다. 그렇기에 tensor에 대한 수정 사항이 ndarray에 반영되고, 그 반대의 경우 또한 적용된다는 점을 고려해야 합니다.</p>

<p>또한, 그로 인해 만들어진 tensor의 크기는 그 이후 조정할 수 없습니다. 이와 관련된 공식 문서의 설명은 아래와 같습니다.</p>

<div align="center"> <img src="https://drive.google.com/uc?id=1VfaE2osqXmezYhioaXN2kLW8VzBCjk4u" /> </div>

<p>그렇다면 정말 작동하는지 확인해봅시다.</p>

<p>먼저, <code class="language-plaintext highlighter-rouge">torch.Tensor()</code> 함수를 활용하여 numpy array를 Tensor로 바꾸어봅시다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">arr</span><span class="p">))</span>

<span class="n">arr_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">arr_tensor</span><span class="p">))</span>
</code></pre></div></div>

<p>아래와 같이 해당하는 type이 변경되는 것을 쉽게 확인할 수 있습니다.</p>

<div align="center"> <img src="https://drive.google.com/uc?id=1Wk4zEELWdLsoaOuf-ruHm1Q-V7-I0HEo" /> </div>

<p>다음으로는 <code class="language-plaintext highlighter-rouge">torch.from_numpy()</code> 함수를 활용하여 numpy array를 Tensor로 바꾸어봅시다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">arr2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">arr2</span><span class="p">))</span>

<span class="n">arr_tensor2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">arr2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">arr_tensor2</span><span class="p">))</span>
</code></pre></div></div>

<p>아래와 같이 해당하는 type이 변환되는 것을 확인할 수 있습니다.</p>

<div align="center"><img src="https://drive.google.com/uc?id=1Wk4zEELWdLsoaOuf-ruHm1Q-V7-I0HEo" /></div>

<p>이와 반대로 Pytorch에서 tensor에서 numpy로 변경하기 위해서는 <code class="language-plaintext highlighter-rouge">torch.Tensor.numpy()</code> 구문을 활용할 수 있습니다. 이를 <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html">pytorch 공식문서</a>에서 확인해보면 아래와 같이 간결하게 역할을 확인할 수 있습니다.</p>

<p>앞선 <code class="language-plaintext highlighter-rouge">torch.from_numpy()</code> 와 마찬가지로 <code class="language-plaintext highlighter-rouge">torch.Tensor.numpy()</code> 또한 각 tensor와 ndarray는 같은 메모리를 공유하게 됩니다.</p>

<div align="center"> <img src="https://drive.google.com/uc?id=1OGc3E3BBM3DjMMeanVGkkiEGV0v0BgKB" /> </div>

<p>이제는 <code class="language-plaintext highlighter-rouge">numpy()</code> 를 활용하여 변환된 Tensor를 numpy array로 바꾸어봅시다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">arr_numpy</span> <span class="o">=</span> <span class="n">arr_tensor</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">arr_numpy</span><span class="p">))</span>
</code></pre></div></div>

<p>아래와 같이 <code class="language-plaintext highlighter-rouge">numpy.ndarray</code> 타입으로 변환된 것을 확인할 수 있습니다.</p>

<div align="center"><img src="https://drive.google.com/uc?id=1p-YqWDZnsikTgAA67YuSpayk6Ko2Qtvo" /></div>

<p><br />
<br />
<br /></p>

<hr />

<h2 id="5-실습">5. 실습</h2>

<p>오늘 배운 내용을 직접 타이핑해보는 시간도 가졌습니다!<br />
시간이 여유롭지않아 완벽하게는 못했지만 다음번에는 더 나은 실습들로 마련해볼게요 💯</p>

<h4 id="1-23-형태의-01-사이의-무작위-값으로-이루어진-텐서를-생성해보세요">1. (2,3) 형태의 0~1 사이의 무작위 값으로 이루어진 텐서를 생성해보세요.</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">x</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[-1.1449e+00, -5.8245e-01, -4.2747e-01],
        [ 2.1382e-05, -2.5037e-01,  1.3060e-01]])
</code></pre></div></div>

<h4 id="2-위-텐서의-타입을-출력해보세요dtype">2. 위 텐서의 타입을 출력해보세요.(dtype)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="p">.</span><span class="n">dtype</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.float32
</code></pre></div></div>

<h4 id="3-1부터-3까지-순서대로-이루어진-int-type의-텐서를-생성해보세요">3. 1부터 3까지 순서대로 이루어진 int type의 텐서를 생성해보세요.</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">y</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([1, 2, 3])
</code></pre></div></div>

<h4 id="4-첫번째-생성한-텐서와-두번째-생성한-텐서의-곱을-하고-연산이-되는-이유는-무엇인가요">4. 첫번째 생성한 텐서와 두번째 생성한 텐서의 곱을 하고 연산이 되는 이유는 무엇인가요?</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="o">*</span><span class="n">y</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[-1.1449e+00, -1.1649e+00, -1.2824e+00],
        [ 2.1382e-05, -5.0074e-01,  3.9180e-01]])
</code></pre></div></div>

<h4 id="5-첫번째-생성한-텐서를-transpose하고-첫번째-생성한-텐서와-행렬곱을-진행해보세요">5. 첫번째 생성한 텐서를 Transpose하고 첫번째 생성한 텐서와 행렬곱을 진행해보세요</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">z</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">T</span>
<span class="n">z</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[-1.1449e+00,  2.1382e-05],
        [-5.8245e-01, -2.5037e-01],
        [-4.2747e-01,  1.3060e-01]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">z</span><span class="o">@</span><span class="n">x</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1.3107, 0.6668, 0.4894],
        [0.6668, 0.4019, 0.2163],
        [0.4894, 0.2163, 0.1998]])
</code></pre></div></div>

<h4 id="6-행렬곱을-진행한-텐서와-첫번째-생성한-텐서를-concatenate하세요">6. 행렬곱을 진행한 텐서와 첫번째 생성한 텐서를 Concatenate하세요</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[-1.1449e+00, -5.8245e-01, -4.2747e-01],
        [ 2.1382e-05, -2.5037e-01,  1.3060e-01]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z</span><span class="o">@</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[ 1.3107e+00,  6.6682e-01,  4.8940e-01],
        [ 6.6682e-01,  4.0193e-01,  2.1628e-01],
        [ 4.8940e-01,  2.1628e-01,  1.9979e-01],
        [-1.1449e+00, -5.8245e-01, -4.2747e-01],
        [ 2.1382e-05, -2.5037e-01,  1.3060e-01]])
</code></pre></div></div>

<h4 id="7-두번째에-만든-텐서를-unsqueeze하고-shape를-출력하세요-dim1">7. 두번째에 만든 텐서를 unsqueeze하고 shape를 출력하세요 (dim=1)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[1],
        [2],
        [3]])
torch.Size([3, 1])
</code></pre></div></div>

<h4 id="8-unsqueeze한-텐서를-squeeze하세요-shape를-출력하세요-dim1">8. unsqueeze한 텐서를 squeeze하세요 shape를 출력하세요 (dim=1)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">k</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">k</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">k</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([1, 2, 3])
torch.Size([3])
</code></pre></div></div>

<h4 id="9-0부터-5의-숫자로-이루어진-23형태의-텐서고-norm을-구해주세요">9. 0부터 5의 숫자로 이루어진 (2,3)형태의 텐서고 Norm을 구해주세요</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">A</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0., 1., 2.],
        [3., 4., 5.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(7.4162)
</code></pre></div></div>

<h4 id="10-해당-코드가-돌아가도록-알맞은-파라미터를-추가해주세요">10. 해당 코드가 돌아가도록 알맞은 파라미터를 추가해주세요!</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># input tensor
</span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># expected output
</span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Gradient function for z = </span><span class="si">{</span><span class="n">z</span><span class="p">.</span><span class="n">grad_fn</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Gradient function for loss = </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">grad_fn</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Gradient function for z = &lt;AddBackward0 object at 0x7f5523e0a210&gt;
Gradient function for loss = &lt;BinaryCrossEntropyWithLogitsBackward0 object at 0x7f5523e0a5d0&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">w</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[0.0139, 0.3273, 0.0794],
        [0.0139, 0.3273, 0.0794],
        [0.0139, 0.3273, 0.0794],
        [0.0139, 0.3273, 0.0794],
        [0.0139, 0.3273, 0.0794]])
tensor([0.0139, 0.3273, 0.0794])
</code></pre></div></div>

<h4 id="11-아래-false가-나온-결과와-같은-결과가-나오도록-코드를-완성해주세요">11. 아래 False가 나온 결과와 같은 결과가 나오도록 코드를 완성해주세요.</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="k">print</span><span class="p">(</span><span class="n">z</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="k">print</span><span class="p">(</span><span class="n">z</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>True
False
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="n">z_det</span> <span class="o">=</span> <span class="n">z</span><span class="p">.</span><span class="n">detach</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">z_det</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>False
</code></pre></div></div>

<h4 id="12-코랩-sample-data의-california_housing_train에서-median_house_value를-target으로-하고-tensor형태로-변환해보세요">12. 코랩 Sample data의 california_housing_train에서 median_house_value를 target으로 하고 Tensor형태로 변환해보세요</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/content/sample_data/california_housing_train.csv'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \
0        -114.31     34.19                15.0       5612.0          1283.0   
1        -114.47     34.40                19.0       7650.0          1901.0   
2        -114.56     33.69                17.0        720.0           174.0   
3        -114.57     33.64                14.0       1501.0           337.0   
4        -114.57     33.57                20.0       1454.0           326.0   
...          ...       ...                 ...          ...             ...   
16995    -124.26     40.58                52.0       2217.0           394.0   
16996    -124.27     40.69                36.0       2349.0           528.0   
16997    -124.30     41.84                17.0       2677.0           531.0   
16998    -124.30     41.80                19.0       2672.0           552.0   
16999    -124.35     40.54                52.0       1820.0           300.0   

       population  households  median_income  median_house_value  
0          1015.0       472.0         1.4936             66900.0  
1          1129.0       463.0         1.8200             80100.0  
2           333.0       117.0         1.6509             85700.0  
3           515.0       226.0         3.1917             73400.0  
4           624.0       262.0         1.9250             65500.0  
...           ...         ...            ...                 ...  
16995       907.0       369.0         2.3571            111400.0  
16996      1194.0       465.0         2.5179             79000.0  
16997      1244.0       456.0         3.0313            103600.0  
16998      1298.0       478.0         1.9797             85800.0  
16999       806.0       270.0         3.0147             94600.0  

[17000 rows x 9 columns]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',
       'total_bedrooms', 'population', 'households', 'median_income',
       'median_house_value'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">dummy_na</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">head</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \
0    -114.31     34.19                15.0       5612.0          1283.0   
1    -114.47     34.40                19.0       7650.0          1901.0   
2    -114.56     33.69                17.0        720.0           174.0   
3    -114.57     33.64                14.0       1501.0           337.0   
4    -114.57     33.57                20.0       1454.0           326.0   

   population  households  median_income  
0      1015.0       472.0         1.4936  
1      1129.0       463.0         1.8200  
2       333.0       117.0         1.6509  
3       515.0       226.0         3.1917  
4       624.0       262.0         1.9250  
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">head</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \
0    -114.31     34.19                15.0       5612.0          1283.0   
1    -114.47     34.40                19.0       7650.0          1901.0   
2    -114.56     33.69                17.0        720.0           174.0   
3    -114.57     33.64                14.0       1501.0           337.0   
4    -114.57     33.57                20.0       1454.0           326.0   

   population  households  median_income  
0      1015.0       472.0         1.4936  
1      1129.0       463.0         1.8200  
2       333.0       117.0         1.6509  
3       515.0       226.0         3.1917  
4       624.0       262.0         1.9250  
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">values</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">targets</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensor([[-114.3100,   34.1900,   15.0000,  ..., 1015.0000,  472.0000,
             1.4936],
         [-114.4700,   34.4000,   19.0000,  ..., 1129.0000,  463.0000,
             1.8200],
         [-114.5600,   33.6900,   17.0000,  ...,  333.0000,  117.0000,
             1.6509],
         ...,
         [-124.3000,   41.8400,   17.0000,  ..., 1244.0000,  456.0000,
             3.0313],
         [-124.3000,   41.8000,   19.0000,  ..., 1298.0000,  478.0000,
             1.9797],
         [-124.3500,   40.5400,   52.0000,  ...,  806.0000,  270.0000,
             3.0147]], dtype=torch.float64),
 tensor([ 66900.,  80100.,  85700.,  ..., 103600.,  85800.,  94600.],
        dtype=torch.float64))
</code></pre></div></div>

<p><br />
<br />
<br /></p>

<hr />

<h2 id="6-마치며">6. 마치며</h2>

<p>너무 많은 내용을 했었던 2주차였습니다!!<br />
Tensor를 어떤 식으로 만지고 변경할 수 있는지 알게되는 2주차였으면 좋겠습니다!</p>

  </article>
  <br>

  <hr/><br>

  <div class="author">
    
    <table>
        <tr>
          <td rowspan="3" style="padding-right: 10px"><img class="author-pic" src="https://github.com/.png" alt=""></td>
          <td><b><h2 rel="author"></h2></b></td>
        </tr>
      <tr>
        <td><p rel="author"></p>
        </td>
      </tr>
      <tr>
        <td>
          <a rel="author" href="https://github.com/" target="_blank"><i class="fa fa-github fa-2x"></i></a>&nbsp&nbsp
          
        </td>
      </tr>
    </table>

  </div>


  <br>
  <hr/>
  <div>
    <script src="https://utteranc.es/client.js"
        repo="gdsc-seoultech/blog-comments"
        issue-term="pathname"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>
  </div>

</div>
<script src="/js/toc.js"></script>
      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper" align="center">
  	<h4>This site was built using <a href="http://jekyllrb.com" target="_blank">Jekyll</a> and is hosted on <a href="https://github.com" target="_blank">Github</a>. &#169; GDSC Seoultech</h4>
  </div>

</footer>


  </body>
</html>
